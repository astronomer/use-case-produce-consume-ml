{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an MLFlow experiment\n",
    "import mlflow\n",
    "\n",
    "experiment_name='astro_ml_dev'\n",
    "tags={'project': 'astro_ml', 'model':'RidgeCV'}\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_name, tags=tags)\n",
    "except (mlflow.exceptions.MlflowException, mlflow.exceptions.RestException) as e:\n",
    "    if \"already exists\" in e.args[0]:\n",
    "        experiment = mlflow.search_experiments(filter_string=\"name = '\"+experiment_name+\"'\")\n",
    "        experiment_id = experiment[0].experiment_id\n",
    "\n",
    "\n",
    "#Set S3 access for MLFlow artifact writing.\n",
    "import os\n",
    "os.environ['AWS_ACCESS_KEY_ID']='minioadmin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']='minioadmin'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download data and save it to S3\n",
    "from s3fs import S3FileSystem\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(download_if_missing=True, as_frame=True).frame\n",
    "\n",
    "fs = S3FileSystem(key='minioadmin', secret='minioadmin', client_kwargs={'endpoint_url': \"http://localhost:9000/\"})\n",
    "with fs.open('s3://data/housing_df.csv', 'wb') as f:\n",
    "    f.write(housing_df.to_csv(index=False).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure we can read it back\n",
    "from s3fs import S3FileSystem\n",
    "import pandas as pd\n",
    "fs = S3FileSystem(key='minioadmin', secret='minioadmin', client_kwargs={'endpoint_url': \"http://localhost:9000/\"})\n",
    "\n",
    "with fs.open('s3://data/housing_df.csv', 'rb') as f:\n",
    "    housing_df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "import mlflow\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "target = 'MedHouseVal'\n",
    "X = housing_df.drop(target, axis=1)\n",
    "y = housing_df[target]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name='Scaler') as run:\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    mlflow.sklearn.log_model(scaler, artifact_path='scaler')\n",
    "    mlflow.log_metrics(pd.DataFrame(scaler.mean_, index=X.columns)[0].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a model\n",
    "\n",
    "import mlflow\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "target = 'MedHouseVal'\n",
    "\n",
    "model = RidgeCV(alphas=np.logspace(-3, 1, num=30))\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name='RidgeCV') as run:\n",
    "    reg = model.fit(X, y)\n",
    "\n",
    "run_id=run.info.run_id\n",
    "\n",
    "#return run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the data\n",
    "\n",
    "import mlflow\n",
    "\n",
    "logged_model = 'runs:/'+run_id+'/model'\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "X['pred'] = loaded_model.predict(X)\n",
    "X[target] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write data with predictions to S3\n",
    "from s3fs import S3FileSystem\n",
    "\n",
    "fs = S3FileSystem(key='minioadmin', secret='minioadmin', client_kwargs={'endpoint_url': \"http://localhost:9000/\"})\n",
    "with fs.open('s3://data/housing_pred.csv', 'wb') as f:\n",
    "    f.write(X.to_csv(index=False).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('snowpark_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "084830ef4bd753686d3b491d998ecd90799bdf0b5dcd9517c01902e8176a4901"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
